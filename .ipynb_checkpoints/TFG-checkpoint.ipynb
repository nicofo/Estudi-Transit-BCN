{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "reload(sys) \n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dades d'incidencies de trànsit a Barcelona de la **Guardia Urbana de Barcelona** descarregades el dia 28 d'Abril del 2016 de [OpenDataBcn](http://opendata.bcn.cat/opendata/ca/catalog/GUARDIA%20URBANA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importem tots els *CSV* a Pandas DataFrame. <br> \n",
    "Hi ha hagut molts problemes ja que ho importavem amb cofificació UTF-8 i hem descobert que es Latín 1(iso-8859-1) <br>\n",
    "Els vehicles van amb OS2-850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Número d'expedient              object\n",
       "Codi districte                   int64\n",
       "Nom districte                   object\n",
       "NK barri                        object\n",
       "Nom barri                       object\n",
       "Codi carrer                      int64\n",
       "Nom carrer                      object\n",
       "Num postal caption              object\n",
       "Descripció dia setmana          object\n",
       "Dia de setmana                   int64\n",
       "Descripció tipus dia            object\n",
       "NK Any                           int64\n",
       "Mes de any                       int64\n",
       "Nom mes                         object\n",
       "Dia de mes                       int64\n",
       "Hora de dia                      int64\n",
       "Descripció torn                 object\n",
       "Descripció causa vianant        object\n",
       "Número de morts                  int64\n",
       "Número de lesionats lleus        int64\n",
       "Número de lesionats greus        int64\n",
       "Número de víctimes               int64\n",
       "Número de vehicles implicats     int64\n",
       "Coordenada UTM (Y)              object\n",
       "Coordenada UTM (X)              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "general=dict()\n",
    "persones=dict()\n",
    "vehicles=dict()\n",
    "tipus=dict()\n",
    "sizeYears=6\n",
    "\n",
    "general[0]=pd.read_csv(\"general/ACCIDENTS_GU_BCN_2010.csv\",sep=',', encoding='iso-8859-1')\n",
    "persones[0]=pd.read_csv(\"persones/ACCIDENTS_PERSONES_GU_BCN_201\"+str(0)+\".csv\",sep=';', encoding='iso-8859-1')\n",
    "tipus[0]=pd.read_csv(\"tipologia/ACCIDENTS_TIPUS_GU_BCN_201\"+str(0)+\".csv\",sep=';', encoding='cp850')\n",
    "vehicles[0]=pd.read_csv(\"vehicles/2010_ACCIDENTS_VEHICLES_GU_BCN_2010.csv\",sep=';', encoding='cp850')\n",
    "\n",
    "general[1]=pd.read_csv(\"general/ACCIDENTS_GU_BCN_2011.csv\",sep=',', encoding='iso-8859-1')\n",
    "persones[1]=pd.read_csv(\"persones/ACCIDENTS_PERSONES_GU_BCN_201\"+str(1)+\".csv\",sep=';', encoding='iso-8859-1')\n",
    "tipus[1]=pd.read_csv(\"tipologia/ACCIDENTS_TIPUS_GU_BCN_201\"+str(1)+\".csv\",sep=';', encoding='cp850')\n",
    "vehicles[1]=pd.read_csv(\"vehicles/2011_ACCIDENTS_VEHICLES_GU_BCN_2011.csv\",sep=';', encoding='cp850')\n",
    "\n",
    "general[2]=pd.read_csv(\"general/ACCIDENTS_GU_BCN_2012.csv\",sep=',', encoding='iso-8859-1')\n",
    "persones[2]=pd.read_csv(\"persones/ACCIDENTS_PERSONES_GU_BCN_201\"+str(2)+\".csv\",sep=';', encoding='iso-8859-1')\n",
    "tipus[2]=pd.read_csv(\"tipologia/ACCIDENTS_TIPUS_GU_BCN_201\"+str(2)+\".csv\",sep=';', encoding='cp850')\n",
    "vehicles[2]=pd.read_csv(\"vehicles/2012_ACCIDENTS_VEHICLES_GU_BCN_2012.csv\",sep=';', encoding='cp850')\n",
    "\n",
    "general[3]=pd.read_csv(\"general/ACCIDENTS_GU_BCN_2013.csv\",sep=',', encoding='iso-8859-1')\n",
    "persones[3]=pd.read_csv(\"persones/ACCIDENTS_PERSONES_GU_BCN_201\"+str(3)+\".csv\",sep=';', encoding='iso-8859-1')\n",
    "tipus[3]=pd.read_csv(\"tipologia/ACCIDENTS_TIPUS_GU_BCN_201\"+str(3)+\".csv\",sep=';', encoding='cp850')\n",
    "vehicles[3]=pd.read_csv(\"vehicles/2013_ACCIDENTS_VEHICLES_GU_BCN_2013.csv\",sep=';', encoding='cp850')\n",
    "\n",
    "general[4]=pd.read_csv(\"general/ACCIDENTS_GU_BCN_2014.csv\",sep=';', encoding='iso-8859-1')\n",
    "persones[4]=pd.read_csv(\"persones/ACCIDENTS_PERSONES_GU_BCN_201\"+str(4)+\".csv\",sep=';', encoding='iso-8859-1')\n",
    "tipus[4]=pd.read_csv(\"tipologia/ACCIDENTS_TIPUS_GU_BCN_201\"+str(4)+\".csv\",sep=';', encoding='cp850')\n",
    "vehicles[4]=pd.read_csv(\"vehicles/2014_ACCIDENTS_VEHICLES_GU_BCN_2014.csv\",sep=';', encoding='cp850')\n",
    "\n",
    "general[5]=pd.read_csv(\"general/ACCIDENTS_GU_BCN_2015.csv\",sep=';', encoding='iso-8859-1')\n",
    "persones[5]=pd.read_csv(\"persones/ACCIDENTS_PERSONES_GU_BCN_201\"+str(5)+\".csv\",sep=';', encoding='iso-8859-1')\n",
    "tipus[5]=pd.read_csv(\"tipologia/ACCIDENTS_TIPUS_GU_BCN_201\"+str(5)+\".csv\",sep=';', encoding='cp850')\n",
    "vehicles[5]=pd.read_csv(\"vehicles/2015_ACCIDENTS_VEHICLES_GU_BCN_2015.csv\",sep=';', encoding='cp850')\n",
    "\n",
    "    #cotxes.append(pd.read_csv(\"vehicles/\"+i+\"_ACCIDENTS_VEHICLES_GU_BCN_201\"+i+\".csv\",sep=';', encoding='iso-8859-1')\n",
    "    #data = pd.merge(pd.merge(pd.merge(general,cotxes), persones), tipus).T.drop_duplicates().T\n",
    "\n",
    "#data.to_csv(\"dadesAccidents.csv\", sep=';', encoding='utf32')\n",
    "#general[5].columns=['Hola']+general[5].columns[1:]\n",
    "general[0].dtypes\n",
    "#data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canviem els **headres**.<br>\n",
    "Treiem els accents, els espais i els apostrofs. També ho posem tot en minuscula.\n",
    "<br>**Referencies:**<br>\n",
    "http://stackoverflow.com/questions/517923/what-is-the-best-way-to-remove-accents-in-a-python-unicode-string <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "def firstUpper(x):\n",
    "    x=x[0].upper()+x[1:]\n",
    "    return x\n",
    "\n",
    "def convertHeader(x):\n",
    "    #to Lower case\n",
    "    if \" \" in x:\n",
    "        x = x.lower() \n",
    "    x = remove_accents(x)\n",
    "    \n",
    "    # Replace spaces for  \"\"\n",
    "    words=x.split()\n",
    "    words=[firstUpper(x) for x in words]\n",
    "    x=\"\".join(words)\n",
    "    \n",
    "    # Replace all character that is not a letter or space for \"\"\n",
    "    x = re.sub('[^a-z, A-Z\\ ]+', \"\", x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "for i in range(sizeYears):\n",
    "    general[i].columns=general[i].columns.map(convertHeader)\n",
    "    persones[i].columns=persones[i].columns.map(convertHeader)\n",
    "    tipus[i].columns=tipus[i].columns.map(convertHeader)\n",
    "    vehicles[i].columns=vehicles[i].columns.map(convertHeader)\n",
    "    \n",
    "print general[i].columns\n",
    "print persones[i].columns\n",
    "print tipus[i].columns\n",
    "print vehicles[i].columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adherim columnes que ens poden ser utils:\n",
    "\n",
    "+ DataNumeric(Per ordenació)\n",
    "+ Data(Per mostrar)\n",
    "+ Lat(Latitud de coordenades LatLon)\n",
    "+ Lon(Longitud de coordenades LatLon)\n",
    "\n",
    "Ho posarem als DataFrames *general* ja que son els que utilitzarem de base\n",
    "\n",
    "Utilitzarem el Package [UTM](https://pypi.python.org/pypi/utm) per pasar de UTM a LatLon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import utm\n",
    "#Functions for mapping\n",
    "def toStr(x):\n",
    "    return str(x)\n",
    "\n",
    "def toInt(x):\n",
    "    return int(x)\n",
    "def to2Dig(x):\n",
    "    return \"%02d\" % (x,)\n",
    "def utmToLat(x):\n",
    "    coor=x.split(\"/\")\n",
    "    try:\n",
    "        lat=utm.to_latlon(float(str(coor[0]).replace(',', '.')), float(str(coor[1]).replace(',', '.')),  31, 'T')[0]\n",
    "    except:\n",
    "        lat=-1\n",
    "    return lat\n",
    "def utmToLon(x):\n",
    "    coor=x.split(\"/\")\n",
    "    try:\n",
    "        lat=utm.to_latlon(float(str(coor[0]).replace(',', '.')), float(str(coor[1]).replace(',', '.')),  31, 'T')[1]    \n",
    "    except:\n",
    "        lat=-1\n",
    "    return lat\n",
    "\n",
    "for i in range(sizeYears):\n",
    "    general[i]['DataNumeric']=general[i][\"NkAny\"].map(toStr)+\"\"+ general[i][\"MesDeAny\"].map(to2Dig)+''+general[i][\"DiaDeMes\"].map(to2Dig)\n",
    "    general[i]['DataNumeric']=general[i]['DataNumeric'].map(toInt)\n",
    "    general[i]['Data']=general[i][\"DiaDeMes\"].map(to2Dig)+\"-\"+ general[i][\"MesDeAny\"].map(to2Dig)+'-'+general[i][\"NkAny\"].map(toStr)\n",
    "    general[i]['CoordUTM']=general[i][\"CoordenadaUtmx\"].map(toStr)+\"/\"+general[i][\"CoordenadaUtmy\"].map(toStr)\n",
    "    general[i]['Lat']=general[i]['CoordUTM'].map(utmToLat)\n",
    "    general[i]['Lon']=general[i]['CoordUTM'].map(utmToLon)\n",
    "    general[i]['LatLon']=general[i]['Lat'].map(toStr)+\", \"+general[i]['Lon'].map(toStr)\n",
    "    \n",
    "print general[0][['DataNumeric','Data','CoordUTM', 'Lat', 'Lon']]\n",
    "print general[0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print general[0].dtypes\n",
    "print tipus[0].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminem totes les columnes que no necessitarem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(sizeYears):\n",
    "    general[i].drop('CoordUTM', axis=1, inplace=True)\n",
    "    '''\n",
    "    persones[i].drop('column_name', axis=1, inplace=True)\n",
    "    tipus[i].drop('column_name', axis=1, inplace=True)\n",
    "    vehicles[i].drop('column_name', axis=1, inplace=True)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
